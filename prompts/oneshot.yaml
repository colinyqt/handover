name: "One-Shot Clause Extraction and Best-Fit Recommendation"
description: "Extracts clauses from a tender analysis file and runs FAISS semantic search to find the best-fit meters in a single flow."
version: "1.0"

inputs:
  - name: "analysis_file"
    type: "file"
    description: "Tender analysis output file with extracted clauses and specifications"
  - name: "embedding_model"
    type: "text"
    required: false
    default: "C:/Users/cyqt2/Database/overhaul/jina_reranker/minilm-embedding"
    description: "(Optional) Embedding model to use for semantic search. Example: './jina_reranker/minilm-embedding'. If not set, uses this default."

processing_steps:
  # Step 0: Chunk the analysis file into smaller pieces for LLM clause extraction
  - name: "chunk_analysis_file"
    description: "Chunk the analysis file into smaller pieces to avoid LLM context limits."
    type: python
    code: |
      import re
      content = context['inputs']['analysis_file']['content']
      # Simple chunking: split by section/clause headers, keeping the header
      # with the following chunk. This is done using a positive lookahead `(?=...)`.
      # This ensures each chunk (except the first) starts with its clause header,
      # providing necessary context for the LLM.
      chunks = re.split(r'(?=(?:Section \d+[A-Z]?|Clause \d+(?:\.\d+)*))', content)
      # If not enough chunks, fallback to fixed-size chunks
      if len(chunks) < 2:
          chunk_size = 8000
          chunks = [content[i:i+chunk_size] for i in range(0, len(content), chunk_size)]
      # Remove empty or whitespace-only chunks
      chunks = [c.strip() for c in chunks if c.strip()]
      print(f"[DEBUG] Chunked analysis file into {len(chunks)} pieces.")
      result = {'chunks': chunks}

  # Step 0b: Debug - Show exactly what is passed to the LLM foreach step
  - name: "debug_show_chunks_for_llm"
    description: "Display exactly what is passed to the LLM foreach step, including type and content."
    type: python
    dependencies: [chunk_analysis_file]
    code: |
      chunks = context['dep_chunk_analysis_file']['chunks']
      print("[DEBUG] Chunks to be passed to LLM foreach step:")
      for idx, chunk in enumerate(chunks):
          print(f"[CHUNK {idx}] type={type(chunk)} length={len(chunk)}\n{repr(chunk)[:500]}")
      result = {'chunks': chunks}

  # Step 1: Extract clauses from each chunk (chunked clause extraction)
  - name: "extract_clauses"
    description: "Extract meter requirements from each chunk of the analysis file (grouped by clause)"
    type: llm
    dependencies: [chunk_analysis_file]
    foreach: context['chunk_analysis_file']['chunks']
    input: |
      IMPORTANT: Output ONLY valid, complete JSON. DO NOT include any Markdown, code fences, or any text before or after the JSON. DO NOT include ```json or any explanation. Output ONLY the JSON object, starting with { and ending with }. Your output MUST be valid JSON, never truncated, and must always end with the correct number of closing brackets and braces.

      Extract all key meter requirements and specifications from the following tender analysis chunk, grouping them by clause or meter type (e.g., "Multi-Function Electronic Meters (1.20.4)", "Power Quality Meters (1.20.5)", etc.):
      {{item}}

      Return your answer as a JSON object with:
        - "requirements": a list of objects, one per clause, each with:
            - "clause": the clause or meter type name
            - "features": a list of all requirements/features for that clause
            - "text": the full clause text (for semantic search)
        - "text": the full extracted requirements section as a single string, including all bullet points and details (for semantic search and fallback extraction)

      Example output:
      {
        "requirements": [
          {
            "clause": "Multi-Function Electronic Meters (1.20.4)",
            "features": [
              "True RMS Current ±0.5%",
              "True RMS Volts ±0.5%"
            ],
            "text": "Full clause text here"
          }
        ],
        "text": "- True RMS Current ±0.5%\n- True RMS Volts ±0.5%"
      }

      If you cannot find any requirements, return an empty list for "requirements" and an empty string for "text".

      FINAL REMINDER: Output ONLY valid, complete JSON. DO NOT include any Markdown, code fences, or extra text. Double check that your output is never truncated and always ends with the correct number of closing brackets and braces. If you are unsure, repeat the output with all closing brackets and braces at the end.
    output_key: chunked_clauses
    timeout: 60

  # Step 2: Inject FAISSProcessor into context (from faiss_clauses_bestfit.yaml)
  - name: "inject_faiss_processor"
    description: "Inject FAISSProcessor into the pipeline context."
    type: python
    code: |
      from faiss_processor import FAISSProcessor
      context['faiss_processor'] = FAISSProcessor()
      print("[DEBUG] FAISSProcessor injected into context.")

  # Step 3: Load clauses from all chunked LLM outputs
  - name: "load_clauses_from_memory"
    description: "Load extracted clauses and features from all chunked LLM outputs."
    type: python
    dependencies: [extract_clauses]
    code: |
      import json
      import re
      chunked_outputs = context.get('dep_extract_clauses', [])
      clause_map = {}
      for raw in chunked_outputs:
          # Accept both dict and string outputs from LLM step
          if isinstance(raw, dict) and 'raw_response' in raw:
              raw_string = raw['raw_response']
          elif isinstance(raw, str):
              raw_string = raw
          else:
              raw_string = str(raw)

          # Remove any markdown code fences and extra text
          # Accept output that is either a valid JSON string or a dict
          # Try direct JSON parse first
          data = None
          try:
              data = json.loads(raw_string)
          except Exception:
              # If not valid JSON, try to extract JSON object from string
              json_match = re.search(r'\{.*\}', raw_string, re.DOTALL)
              if json_match:
                  json_string = json_match.group(0)
                  try:
                      data = json.loads(json_string)
                  except Exception:
                      data = None
          if isinstance(data, dict):
              chunk_clauses = data.get('requirements', [])
              if isinstance(chunk_clauses, list):
                  for clause in chunk_clauses:
                      name = clause.get('clause')
                      if not name:
                          continue
                      if name not in clause_map:
                          clause_map[name] = {'features': set(), 'text': []}
                      clause_map[name]['features'].update(clause.get('features', []))
                      if clause.get('text'):
                          clause_map[name]['text'].append(clause['text'])
          # If data is not a dict, skip this chunk
      # Final output: deduplicated and merged clauses
      deduped_clauses = []
      for name, data in clause_map.items():
          deduped_clauses.append({
              'clause': name,
              'features': list(data['features']),
              'text': '\n'.join(data['text'])
          })
      result = {'clauses': deduped_clauses}


  # Step 4: Use LLM to break down features (from faiss_clauses_bestfit.yaml)
  - name: "llm_breakdown_features"
    description: "Use the LLM to break down each feature into atomic requirements for FAISS search."
    type: llm
    dependencies: [load_clauses_from_memory]
    foreach: context['load_clauses_from_memory']['clauses']
    input: |
      You are an expert requirements engineer. For each feature in the clause below, break it down into a list of atomic, normalized requirements suitable for semantic search in a requirements database. 
      
      Return ONLY a valid JSON object mapping each original feature string to a list of atomic requirements. 
      Do not include any explanation, greeting, or extra text. 
      If a feature is already atomic, return it as a single-item list. 
      
      Example output:
      {"Feature 1": ["atomic req 1", "atomic req 2"], "Feature 2": ["atomic req 3"]}
      
      Clause: {{item['clause']}}
      Features:
      {% for feature in item['features'] %}
      - {{feature}}
      {% endfor %}
    output_key: atomic_requirements_by_feature

  # Step 5: Aggregate atomic requirements (from faiss_clauses_bestfit.yaml)
  - name: "aggregate_atomic_requirements"
    description: "Aggregate atomic requirements from all clauses into a single mapping."
    type: python
    dependencies: [llm_breakdown_features]
    code: |
      import json
      # The result from a 'foreach' LLM step is a list of dictionaries (or strings).
      list_of_atomic_maps = context.get('dep_llm_breakdown_features', [])
      print(f"[DEBUG] Received list of atomic maps from LLM breakdown: {list_of_atomic_maps}")

      final_atomic_map = {}
      # The LLM is supposed to return a JSON string which gets parsed into a dict.
      # Sometimes it might just be a dict. Handle both cases.
      for item in list_of_atomic_maps:
          atomic_map = {}
          # The item could be a string (JSON) or already a dict
          if isinstance(item, str):
              try:
                  # The LLM might wrap the JSON in markdown
                  if '```json' in item:
                      item = item.split('```json\\n', 1)[1].split('```', 1)[0]
                  atomic_map = json.loads(item)
              except (json.JSONDecodeError, IndexError) as e:
                  print(f"[ERROR] Could not parse JSON from LLM breakdown output: {item}. Error: {e}")
                  continue
          elif isinstance(item, dict):
              atomic_map = item
          
          if isinstance(atomic_map, dict):
              final_atomic_map.update(atomic_map)
          else:
              print(f"[WARN] Expected a dictionary from LLM breakdown, but got {type(atomic_map)}")

      if not final_atomic_map:
          print("[WARN] The final aggregated atomic map is empty.")

      print(f"[DEBUG] Aggregated atomic requirements: {final_atomic_map}")
      result = {'atomic_requirements_by_feature': final_atomic_map}

  # Step 6: Run semantic search (from faiss_clauses_bestfit.yaml)
  - name: "faiss_semantic_search_by_clause"
    description: "For each clause, run FAISS semantic search on each feature and aggregate meter hits using atomic requirements."
    type: python
    dependencies: [load_clauses_from_memory, aggregate_atomic_requirements, inject_faiss_processor]
    code: |
      faiss_processor = context.get('faiss_processor')
      if not faiss_processor:
          raise RuntimeError("FAISS processor is not available in context.")
      results = []
      for clause in context['dep_load_clauses_from_memory']['clauses']:
          meter_counts = {}
          feature_results = []
          print(f"[DEBUG] Processing clause: {clause['clause']}")
          atomic_map = context.get('dep_aggregate_atomic_requirements', {}).get('atomic_requirements_by_feature', {})
          for feature in clause['features']:
              feature_str = str(feature)
              if feature_str not in atomic_map:
                  print(f"[DEBUG] Feature key not found in atomic_map: {feature_str}")
                  print(f"[DEBUG] Available keys: {list(atomic_map.keys())}")
              atomic_reqs = atomic_map.get(feature_str)
              if isinstance(atomic_reqs, str):
                  atomic_reqs = [atomic_reqs]
              elif not atomic_reqs:
                  atomic_reqs = [feature_str]
              all_meters = []
              all_raw_results = []
              for atomic in atomic_reqs:
                  if not atomic or not str(atomic).strip():
                      continue  # Skip empty atomic requirements
                  print(f"[DEBUG] Querying FAISS with atomic requirement: {atomic}")
                  faiss_results = faiss_processor.query_faiss(atomic, top_k=3)
                  print(f"[DEBUG] FAISS results for atomic '{atomic}': {faiss_results}")
                  for idx, r in enumerate(faiss_results):
                      print(f"[DEBUG] Raw FAISS result {idx} for '{atomic}': {r}")
                  meters = []
                  for r in faiss_results:
                      if 'meter' in r:
                          meters.append(r['meter'])
                      elif 'model_name' in r:
                          meters.append(r['model_name'])
                      elif 'metadata' in r and isinstance(r['metadata'], dict):
                          if 'meter' in r['metadata']:
                              meters.append(r['metadata']['meter'])
                          elif 'model_name' in r['metadata']:
                              meters.append(r['metadata']['model_name'])
                  if not meters:
                      print(f"[DEBUG] No 'meter' field found in FAISS results for '{atomic}'. Available keys: {[list(r.keys()) for r in faiss_results]}")
                  for meter in meters:
                      meter_counts[meter] = meter_counts.get(meter, 0) + 1
                  all_meters.extend(meters)
                  all_raw_results.extend(faiss_results)
              feature_results.append({'feature': feature_str, 'atomic_requirements': atomic_reqs, 'meters': all_meters, 'raw_results': all_raw_results})
          ranked = sorted(meter_counts.items(), key=lambda x: x[1], reverse=True)
          top3 = [{'meter': m, 'hits': c} for m, c in ranked[:3]]
          results.append({
              'clause': clause['clause'],
              'top_meters': top3,
              'feature_results': feature_results
          })
      result = {'results': results}

  # Step 7: Generate human-readable report from FAISS results
  - name: "generate_meter_report"
    description: "Generate a human-readable report summarizing the top three meters per clause, their scores, and a blurb on their shortcomings."
    type: python
    dependencies: [faiss_semantic_search_by_clause]
    code: |
      results = context['dep_faiss_semantic_search_by_clause']['results']
      # Map clause name to full clause text for context
      clause_text_map = {}
      for clause_obj in context.get('dep_load_clauses_from_memory', {}).get('clauses', []):
          if isinstance(clause_obj, dict) and 'clause' in clause_obj and 'text' in clause_obj:
              clause_text_map[clause_obj['clause']] = clause_obj['text']
      report_lines = []
      for clause_result in results:
          clause = clause_result['clause']
          top_meters = clause_result['top_meters']
          feature_results = clause_result['feature_results']
          report_lines.append(f"\n=== Clause: {clause} ===\n")
          # Add the full clause text for context if available
          clause_text = clause_text_map.get(clause)
          if clause_text:
              report_lines.append(f"Clause Text:\n{clause_text}\n")
          for idx, meter_info in enumerate(top_meters):
              meter = meter_info['meter']
              hits = meter_info['hits']
              # Find all features this meter matched
              matched_features = []
              missed_features = []
              for feat in feature_results:
                  if meter in feat['meters']:
                      matched_features.append(feat['feature'])
                  else:
                      missed_features.append(feat['feature'])
              # Try to get a blurb from raw_results
              blurb = None
              for feat in feature_results:
                  for r in feat['raw_results']:
                      meta = r.get('metadata', {})
                      if meta.get('model_name') == meter or meta.get('meter') == meter or r.get('meter') == meter:
                          blurb = meta.get('selection_blurb')
                          if blurb:
                              break
                  if blurb:
                      break
              report_lines.append(f"{idx+1}. {meter} (Score: {hits})")
              if blurb:
                  report_lines.append(f"   - Description: {blurb}")
              if missed_features:
                  report_lines.append(f"   - Shortcomings: Does not meet: {', '.join(missed_features)}")
              else:
                  report_lines.append(f"   - Shortcomings: None. Fully compliant.")
          report_lines.append("")
      result = {'report': '\n'.join(report_lines)}

outputs:
  - type: "text"
    filename: "{{ inputs.analysis_file.basename }}_oneshot_bestfit_report_{{ timestamp }}.txt"
    content: |
      {{ step_results.generate_meter_report.report }}
